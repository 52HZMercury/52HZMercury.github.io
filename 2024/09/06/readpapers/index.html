

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/moon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Mercury">
  <meta name="keywords" content="">
  
    <meta name="description" content="论文笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="ReadPapers">
<meta property="og:url" content="http://example.com/2024/09/06/readpapers/index.html">
<meta property="og:site_name" content="Mercury&#39;s blog">
<meta property="og:description" content="论文笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20240906134037404.png">
<meta property="article:published_time" content="2024-09-06T05:36:46.000Z">
<meta property="article:modified_time" content="2025-11-20T08:33:53.972Z">
<meta property="article:author" content="Mercury">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="语义分割">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20240906134037404.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>ReadPapers - Mercury&#39;s blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/KaTeX/0.15.2/katex.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.0","typing":{"enable":true,"typeSpeed":90,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/newloading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Mercury</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/Post%20Page.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="ReadPapers"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-09-06 13:36" pubdate>
          2024年9月6日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          <!-- compatible with older versions-->
          16k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          52 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">ReadPapers</h1>
            
            <div class="markdown-body">
              
              <h2 id="SegMamba">SegMamba</h2>
<p>通道注意力的本质是什么，mamba采用“并行扫描算法”而非“卷积”来进行模型的循环计算，其是否也考虑了通道维度上的内容，是否存在和原始的CNN一样对所有通道上的内容一视同仁的问题</p>
<p><strong>摘要</strong></p>
<p>摘要。Transformer 架构在建模全局关系方面表现出色。然而，它在处理高维医学图像时带来了巨大的计算挑战。Mamba 作为一种状态空间模型 (SSM)，最近成为一种用于对序列数据中的长距离依赖关系进行建模的著名方法，凭借其出色的内存效率和计算速度在自然语言处理领域表现出色。受其成功的启发，我们推出了 SegMamba，一种新颖的 3D 医学图像分割 Mamba 模型，旨在有效捕获每个尺度的全体积特征内的长距离依赖关系。与基于 Transformer 的方法相比，我们的 SegMamba 在整个体积特征建模方面表现出色，即使体积特征的分辨率为 64 × 64 × 64（序列长度约为 260k），也能保持卓越的处理速度。在三个数据集上进行的综合实验证明了我们的 SegMamba 的有效性和效率。此外，为了促进 3D 结直肠癌 (CRC) 分割研究，我们贡献了一个新的大规模数据集（名为 CRC-500）。SegMamba 的代码和有关 CRC-500 数据集的信息可在以下位置找到：<a target="_blank" rel="noopener" href="https://github.com/gexing/SegMamba">https://github.com/gexing/SegMamba</a></p>
<p><strong>模型</strong></p>
<p>SegMamba 主要由三个组件组成：1）具有多个三向空间 Mamba 块的 3D 特征编码器，用于对不同尺度的全局信息进行建模；2）基于卷积层的 3D 解码器，用于预测分割结果；3）跳跃连接，用于将全局多尺度特征连接到解码器以实现特征重用。图 2 说明了所提出的 SegMamba 的概览。</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20240906134037404.png" srcset="/img/newloading.gif" lazyload alt="Fig. 2. The overview of the proposed SegMamba."></p>
<p>对于 3D 医学图像分割而言，全局特征和多尺度特征建模至关重要。Transformer 架构可以提取全局信息，但在处理过长的特征序列时会产生很大的计算负担。为了减少序列长度，基于 Transformer 架构的方法（例如 UNETR）直接将分辨率为 D × H × W 的 3D 输入下采样为 D 16 × H 16 × W 16。然而，这种方法限制了编码多尺度特征的能力，而多尺度特征对于通过解码器预测分割结果至关重要。为了克服这个限制，我们设计了一个 TSMamba 模块，以实现多尺度和全局特征建模，同时在训练和推理期间保持高效率。</p>
<p>编码器由一个 stem 层和多个 TSMamba 块组成。stem 层提取第一个尺度特征 z0 ∈ R 48× D 2 × H 2 × W 2。 然后，z0 被输入到每个 TSMamba 块和相应的下采样层。</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20240912152351742.png" srcset="/img/newloading.gif" lazyload alt="Fig. 3. (a) The gated spatial convolution. (b) The tri-orientated Mamba."></p>
<p>门控空间卷积 (GSC) Mamba 层通过将 3D 特征展平为 1D 序列来对特征依赖性进行建模。因此，为了在 Mamba 层之前提取空间关系，我们设计了一个门控空间卷积 (GSC) 模块。如图 3 (a) 所示，输入的 3D 特征被送入两个卷积块（一个卷积块包含一个范数、一个卷积和一个非线性层），卷积核大小分别为 3×3×3 和 1×1×1。<br>
然后将这两个特征逐像素相乘，以类似于门机制 [13] 的信息传输进行控制。最后，使用卷积块进一步融合特征，同时利用残差连接重用输入特征。</p>
<p>三向 Mamba (ToM) 在 TSMamba 模块中，为了有效地对高维特征的全局信息进行建模，我们设计了一个三向 Mamba 模块，从三个方向计算特征依赖关系。如图 3 (b) 所示，我们将 3D 输入特征展平为三个序列，以执行相应的特征交互并获得融合的 3D 特征。</p>
<p><strong>结论</strong></p>
<p>提出了第一种基于 Mamba 的通用 3D 医学图像分割方法，称为 SegMamba。我们设计了一个三向 Mamba (ToM) 模块来增强 3D 特征的顺序建模。然后，为了有效地对空间特征进行建模，我们进一步设计了一个门控空间卷积 (GSC) 模块，以在每个 ToM 模块之前增强空间维度中的特征表示。</p>
<p><strong>复现实验</strong></p>
<p>经过一周的安装和配置环境，终于把这个代码给跑了起来，在这里再骂一遍python狗屎的各种版本。超！在看复现数据之前，先了解相关的评价指标</p>
<p><strong>Dice系数</strong></p>
<p>Dice系数是一种集合相似度度量函数，通常用于计算两个样本的相似度，取值范围在[0,1]</p>
<p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>D</mi><mi>i</mi><mi>c</mi><mi>e</mi><mo>=</mo><mfrac><mrow><mn>2</mn><mi mathvariant="normal">∣</mi><mi>X</mi><mo>∩</mo><mi>Y</mi><mi mathvariant="normal">∣</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mi>X</mi><mi mathvariant="normal">∣</mi><mo>+</mo><mi mathvariant="normal">∣</mi><mi>Y</mi><mi mathvariant="normal">∣</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Dice =  \frac{2|X\cap Y|}{|X| + |Y|}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ce</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>其中 |X∩Y| 是X和Y之间的交集，|X|和|Y|分表表示X和Y的元素的个数，其中，分子的系数为2，是因为分母存在重复计算X和Y之间的共同元素的原因</p>
<p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>M</mi><mi>I</mi><mi>o</mi><mi>U</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><mi>X</mi><mo>∩</mo><mi>Y</mi><mi mathvariant="normal">∣</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mi>X</mi><mo>∪</mo><mi>Y</mi><mi mathvariant="normal">∣</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">MIoU = \frac{|X\cap Y|}{|X \cup Y|}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∪</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>MIoU之前已经了解过了，对于二分类的任务来说，二者思想都是<code>交集/并集</code>，但<code>dice</code>并不是在分母上减去交集，而是<code>将交集在分子上算了两次</code>。</p>
<p>对于多分类来说，<code>Dice</code>是将预测结果转为了<code>多通道</code>，而<code>MIoU</code>只在<code>一个通道</code>上计算。</p>
<p><strong>Dice Loss</strong></p>
<p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>d</mi><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mrow><mn>2</mn><mi mathvariant="normal">∣</mi><mi>X</mi><mo>∩</mo><mi>Y</mi><mi mathvariant="normal">∣</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mi>X</mi><mi mathvariant="normal">∣</mi><mo>+</mo><mi mathvariant="normal">∣</mi><mi>Y</mi><mi mathvariant="normal">∣</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">d = 1 - \frac{2|X\cap Y|}{|X| + |Y|}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>这种<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0&amp;spm=1001.2101.3001.7020">损失函数</a>被称为 **Soft Dice Loss，**因为我们直接使用预测概率而不是使用阈值或将它们转换为二进制mask。Soft Dice Loss 将每个类别分开考虑，然后平均得到最后结果</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20240913160120781.png" srcset="/img/newloading.gif" lazyload alt="image-20240913160120781"></p>
<div class = "note note-danger">注意</div>
<p>(1)训练误差曲线非常混乱，很难看出关于收敛的信息。尽管可以检查在验证集上的误差来避开此问题。</p>
<p>(2)Dice Loss比较适用于样本极度不均的情况，一般的情况下，使用 Dice Loss 会对反向传播造成不利的影响，容易使训练变得不稳定。</p>
<p>所以在一般情况下，还是使用交叉熵损失函数。</p>
<p><strong>豪斯多夫距离（Hausdorff distance）</strong></p>
<p>一般使用dice衡量区域的重合程度，使用95%的HD（ Hausdorff Distance）去<span class="label label-danger">衡量边界</span>的重合程度，之所以取95%，是因为要滤去5%的离群点。</p>
<div class = "note note-success">Hausdorff_95 (95% HD) 原理</div>
<p><strong>Hausdorff distance</strong>是描述两组点集之间相似程度的一种量度，它是两个点集之间距离的一种定义形式：假设有两组集合A={a1,…,ap},B={b1,…,bq},则这两个点集合之间的Hausdorff distance定义为：</p>
<p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>h</mi><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>h</mi><mo stretchy="false">(</mo><mi>B</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H(A,B)=max(h(A,B),h(B,A))             (1)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">A</span><span class="mclose">))</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span></p>
<p>其中,</p>
<p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mi>a</mi><mo>∈</mo><mi>A</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mi>b</mi><mo>∈</mo><mi>B</mi><mtext>‖</mtext><mi>a</mi><mo>−</mo><mi>b</mi><mtext>‖</mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h(A,B)=maxa∈A{minb∈B‖a−b‖} (2)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal">minb</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord">‖</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">b</span><span class="mord">‖</span></span><span class="mopen">(</span><span class="mord">2</span><span class="mclose">)</span></span></span></span></span></p>
<p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mi>b</mi><mo>∈</mo><mi>B</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mi>a</mi><mo>∈</mo><mi>A</mi><mtext>‖</mtext><mi>b</mi><mo>−</mo><mi>a</mi><mtext>‖</mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h(A,B)=maxb∈B{mina∈A‖b−a‖} (3)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord"><span class="mord mathnormal">mina</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">A</span><span class="mord">‖</span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">a</span><span class="mord">‖</span></span><span class="mopen">(</span><span class="mord">3</span><span class="mclose">)</span></span></span></span></span></p>
<p>‖·‖是点集A和B点集间的距离范式。(如:L2或Euclidean距离).</p>
<p><img src="https://pic2.zhimg.com/v2-0f431a4c9e8cf45575d953e2b72fec49_r.jpg" srcset="/img/newloading.gif" lazyload alt="image-20240913160120781"></p>
<p><strong>数据集</strong></p>
<p>BraTS2023 数据集 共包含 1,251 个 3D 脑部 MRI 体积。每个体积包括四种模态（即 T1、T1Gd、T2、T2-FLAIR）和三个分割目标（TC：肿瘤核心、WT：整个肿瘤、ET：增强肿瘤）</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20240912163301804.png" srcset="/img/newloading.gif" lazyload alt="论文给出的实验数据"></p>
<p>这里复现使用的环境为pytroch 2.01,causal-conv1d 1.0.0 , mamba 1.2.0.post1 (site-page里面mamba-ssm换成了mamba 1.0.1)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">用官方项目里的mamba_ssm替换安装在conda环境里的mamba_ssm</span><br>cp -rf mamba_1.0.1/mamba_ssm/ /home/gx/anaconda3/envs/cn_slvs/lib/python3.8/site-packages/<br></code></pre></td></tr></table></figure>
<p>下表就是复现实验的部分<span class = "label label-success">Dice</span>数据：</p>
<table>
<thead>
<tr>
<th style="text-align:center">Epoch</th>
<th style="text-align:center">tc</th>
<th style="text-align:center">wt</th>
<th style="text-align:center">et</th>
<th style="text-align:center">avg</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">19</td>
<td style="text-align:center">0.8111</td>
<td style="text-align:center">0.8987</td>
<td style="text-align:center">0.7715</td>
<td style="text-align:center">0.8270</td>
</tr>
<tr>
<td style="text-align:center">25</td>
<td style="text-align:center">0.8550</td>
<td style="text-align:center">0.9313</td>
<td style="text-align:center">0.8168</td>
<td style="text-align:center">0.8676</td>
</tr>
<tr>
<td style="text-align:center">35</td>
<td style="text-align:center">0.8839</td>
<td style="text-align:center">0.9208</td>
<td style="text-align:center">0.8588</td>
<td style="text-align:center">0.8878</td>
</tr>
<tr>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
</tr>
<tr>
<td style="text-align:center">119</td>
<td style="text-align:center">0.9089</td>
<td style="text-align:center">0.9292</td>
<td style="text-align:center">0.8559</td>
<td style="text-align:center">0.8980</td>
</tr>
</tbody>
</table>
<p>使用<strong>TensorBoard</strong>进行数据可视化</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">tensorboard --logdir=&lt;directory_name&gt;<br><span class="hljs-comment"># 将 directory_name 标记替换为保存数据的目录。 默认是“logs”</span><br><span class="hljs-comment"># 然后用浏览器打开http://localhost:6006/查看</span><br></code></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20240917131419158.png" srcset="/img/newloading.gif" lazyload alt="mean_dice"></p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20240917131533080.png" srcset="/img/newloading.gif" lazyload alt="tc"></p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20240917131712635.png" srcset="/img/newloading.gif" lazyload alt="wt"></p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20240917131751752.png" srcset="/img/newloading.gif" lazyload alt="et"></p>
<h2 id="SwinUMamba">SwinUMamba</h2>
<p><strong>摘要</strong></p>
<p>摘要：准确的医学图像分割需要融合从局部特征到全局依赖的多尺度信息。然而，现有的方法对远程全局信息建模是具有挑战性的，其中卷积神经网络（CNN）受到其局部感受野的限制，视觉变换器（ViTs）受到其注意力机制的高二次复杂性的影响。最近，基于Mamba的模型以其在长序列建模方面的出色能力而受到广泛关注。一些研究表明，这些模型在各种任务中的性能优于流行的视觉模型，具有更高的精度，更低的内存消耗和更少的计算负担。然而，现有的基于Mamba的模型大多是从头开始训练，并且没有探索预训练的力量。本文介绍了一种新的Mambabased模型Swin-Umamba，它是专门为医学图像分割任务设计的，利用基于ImageNet的预训练的优势。我们的实验结果揭示了基于ImageNet的训练在提高Mamba性能方面的重要作用-SwinUAmba与CNN、ViT和最新的基于Mamba的模型相比，表现出上级性能。值得注意的是，在AbdomenMRI、Encoscopy和Microscopy数据集上，Swin-UAmamba比其最接近的对手U-Mamba_Enc的平均得分高出2.72%。Swin-UAmamba的代码和模型可在www.example.com上公开获得<a target="_blank" rel="noopener" href="https://github.com/JiarunLiu/Swin-UMamba%E3%80%82">https://github.com/JiarunLiu/Swin-UMamba。</a></p>
<p><strong>引言</strong></p>
<p>在本文中，我们提出了一个基于Mamba的网络Swin-UMamba，用于2D医学图像分割。Swin-UMamba使用一个通用的编码器，将预训练的视觉模型的强大功能与一个精心设计的解码器集成在一起，用于医学图像分割任务。此外，我们提出了一个变体结构SwinUMamba†，带有一个基于Mamba的解码器，为高效应用提供更少的参数和更低的FLOP。我们的贡献可以总结如下：</p>
<p><em>模型</em></p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20240920152738522.png" srcset="/img/newloading.gif" lazyload alt="Fig. 1. The overall architecture of Swin-UMamba. Swin-UMamba can leverage the power of vision foundation models by loading the weights of pretrained models. Each block within the blue box was initialized with the ImageNet pretrained weights."></p>
<p>Swin-Umamba的三个核心部分分别是：1）数据集（即ImageNet），用于提取不同尺度的特征; 2）解码器，具有多个上采样块，用于预测分割结果; 3）跳过连接，用于弥合低级细节和高级语义之间的差距。我们将在下面的章节中介绍Swin-Umamba的详细结构。</p>
<p><em>VSS块</em></p>
<p>基于[24]的见解，我们将视觉状态空间（VSS）块作为Swin-UMAMBA中的基本单元。VSS块通过采用2D选择性扫描（SS 2D）来解决与2D图像数据相关的挑战。</p>
<p>Swin-Umamba的编码器可以分为5个阶段。第一阶段是茎阶段。它包含一个卷积层，用于2×下采样，具有7×7内核，填充大小为3，Swin-Umamba的第一阶段与VMamba不同，因为我们更喜欢一个逐渐向下的过程，采样过程，每个阶段进行2×下采样。该策略旨在保留低级别细节，这对医学图像分割很重要[8，32]。第二阶段使用2 × 2补丁大小的补丁嵌入层，将特征分辨率保持在原始图像的1/ 4×，这与VMamba中的嵌入特征相同。后续阶段遵循VMamba-Tiny的设计，其中每个阶段由用于2×下采样的补丁合并层和用于高级特征提取的多个VSS块组成。与ViT不同，由于VSS块的因果性质，我们没有采用Swin-Umamba中的位置嵌入[24]。</p>
<p><em>模型结构</em></p>
<p>阶段2到阶段5的VSS块的数量分别为{2，2，9，2}。每个阶段之后的特征维度相对于阶段二次增加，导致D = {48，96，192，384，768}。我们使用来自VMamba-Tiny的ImageNet预训练权重初始化VSS块和补丁合并层，如图1所示。值得注意的是，由于片大小和输入通道的差异，片嵌入块没有用预先训练的权重初始化。</p>
<p>我们遵循常用的U形结构，使用密集的跳跃连接来构建Swin-UAmamba。U-Net及其变体在医学图像分割任务中表现出了显着的效率。该架构利用跳跃连接来恢复低级别细节，并采用编码器-解码器结构来提取高级信息。为了增强U-Net中的原生上采样块，我们引入了两个修改：1）具有剩余连接的额外卷积块以处理跳过连接特征，以及2）每个尺度的额外分割头用于深度监督[33]。</p>
<p><em>SwinUMamba†</em></p>
<p>为了进一步探索Mamba在医学语义分割中的潜力，我们提出了一种基于Mamba解码器的Swin-Umamba变体，即SwinUMamba†。我们将证明SwinUMamba†可以获得与Swin-Umamba相比具有竞争力的结果，同时使用更少的网络参数和更低的计算负担，Swin-Umamba中源自输入图像和2×下采样特征的跳过连接被删除，因为没有对应于它们的解码块。此外，在1×、1/ 4×、1/ 8×和1/ 16×分辨率下应用了深度监控，并结合了额外的分割头（即，将高维特征映射到K的1 × 1卷积）。结合所有这些修改，网络参数的数量从60 M减少到28 M，在AbdomenMRI数据集上，FLOP从68.0G减少到18.9G。关于网络参数和FLOP数量的进一步统计数据见表1、表2和表3。SwinUMamba†的结构见图2。</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20240920154002183.png" srcset="/img/newloading.gif" lazyload alt="Fig. 2. The overall architecture of Swin-UMamba†."></p>
<p><strong>结论</strong></p>
<p>本研究旨在揭示基于ImageNet的预训练对Mambabased模型在二维医学图像分割中的影响。我们提出了一种新的Mambabased模型Swin-UAmamba及其变体SwinUMamba†，两者都能够利用预训练模型的分割任务的能力。我们在各种医学图像分割数据集上的实验表明，基于ImageNet的预训练对基于Mamba的模型有几个优点，包括上级分割精度、稳定的收敛性、过拟合问题的缓解、数据效率和较低的计算资源消耗。我们相信，我们的研究结果突出了预训练在增强基于Mamba的模型在视觉任务中的性能和效率方面的重要性。</p>
<h2 id="Mean-teachers-model">Mean teachers  model</h2>
<blockquote>
<p>Tarvainen A, Valpola H. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results[J]. Advances in neural information processing systems, 2017, 30.</p>
</blockquote>
<p>该算法中教师模型不同学生模型一样，并不是每个step都进行权重更新，而是将学生模型连续训练若干step后产生的权重平均值作为更新权重。教师模型使用学生模型的EMA权重，而不是与学生模型共享权重。论文中表示平均模型权重往往会产生一个比直接使用最终权重更精确的模型。它可以在每一个step完成后即刻聚合之前学习到的所有信息，而不仅仅在每一个epoch。此外，由于EMA提高了所有层的输出质量，而不仅仅是最后一层的输出，因此模型能够更好地表征中层乃至高层语义信息。这些方面造就了该模型相对于Temporal ensemble的两个优势。首先，更准确的标签使学生和教师模型之间发生更快的反馈循环，从而产生更好的精度。其次，这种方法适用于大型数据集和在线学习。</p>
<ol>
<li>对数据进行两种不同的加噪。</li>
<li>将不同噪声增强后的两幅图像分别输入到学生模型的和教师模型。</li>
<li>对输出使用softmax激活，计算学生模型输出与教师模型输出的一致性损失函数， 如果原图像存在label，则还与label计算交叉熵信息损失。</li>
<li>用梯度下降法更新学生模型的权重，教师模型的权重用学生权重的指数移动平均法（EMA）更新（一部分权重来自历史的教师模型权重，另一部分来自于当前的学生模型的权重）：</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20241126163522672.png" srcset="/img/newloading.gif" lazyload alt="image-20241126163522672"></p>
<p><strong>模型缺点</strong>：</p>
<ul>
<li>教师模型的选择对模型性能至关重要。选择一个不合适的教师模型可能会导致性能下降。因此，需要进行一些实验来确定最佳的教师模型。</li>
<li>Mean Teacher 模型仍然需要一些有标签的数据来进行监督训练，尤其是在初期阶段。这意味着它不适用于完全无监督的情况。</li>
<li>Mean Teacher 假设有标签和无标签的数据是从相同的数据分布中生成的。如果这个假设不成立，模型性能可能会受到影响。</li>
<li>Mean Teacher 模型对数据中的噪声和异常值比较敏感。这可能导致模型在存在异常数据的情况下性能下降。</li>
</ul>
<h2 id="ABD半监督医学图像分割">ABD半监督医学图像分割</h2>
<blockquote>
<p>Chi H, Pang J, Zhang B, et al. Adaptive Bidirectional Displacement for Semi-Supervised Medical Image Segmentation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024: 4070-4080.</p>
</blockquote>
<div class = "note note-info">
论文标题
<ul>
    <div>Adaptive Bidirectional Displacement for Semi-Supervised Medical Image Segmentation</div>
</ul>
<ul>
    <div>自适应双向位移半监督医学图像分割</div>
</ul>
    代码链接：
<ul>
    <div>https://github.com/chyupc/ABD</div>
</ul>
</div>
<p><strong>摘要</strong></p>
<p>本文提出了一种自适应双向置换（ABD）方法，用于解决半监督医学图像分割（SSMIS）中的一致性学习挑战。该方法通过设计基于可靠预测置信度的双向补丁置换，生成新的样本，有效抑制了不可控区域，同时保留了输入扰动的影响。此外，为了增强模型对潜在不可控内容的学习能力，提出了针对标记图像的逆置信度双向置换操作，生成了包含更多不可靠信息的样本，以促进模型学习。实验表明，ABD方法在半监督医学图像分割任务中取得了新的最优性能，显著提升了不同基线方法的表现。</p>
<p><em>本文贡献：</em></p>
<p>作者设计了基于可靠预测置信度的双向补丁置换操作。这一创新点在于，它利用了模型对未标记数据的预测结果，根据置信度将图像划分为可靠和不可靠区域，并通过置换这些区域的补丁来生成新的训练样本。这种方法有效地抑制了不可控区域的影响，同时保留了输入扰动对模型训练的积极作用。</p>
<p><strong>逆置信度置换策略：</strong> 针对标记数据，作者提出了逆置信度双向置换操作。这一策略通过在高置信度区域内选择相对不可靠的补丁，在低置信度区域内选择相对可靠的补丁进行置换，生成了包含更多不可靠信息的样本。这一创新点有助于模型学习如何更好地处理潜在的不可控内容，提高了模型的泛化能力。</p>
<p>**实验验证与性能提升：**作者在多个医学图像分割数据集上进行了实验验证，结果表明ABD方法显著提升了半监督医学图像分割的性能。通过与其他先进方法进行比较，ABD方法展现出了优越的性能表现，验证了其在实际应用中的有效性。</p>
<p>**消融实验与组件重要性分析：**为了深入探究ABD方法中各个组件的重要性，作者们进行了消融实验。通过移除基于可靠预测置信度的双向补丁置换和逆置信度双向置换操作，并观察模型性能的变化，作者们发现这两个组件都对ABD方法的性能提升起到了关键作用。这一分析进一步验证了ABD方法的创新性和有效性。</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20241126172507003.png" srcset="/img/newloading.gif" lazyload alt="image-20241126172507003"></p>
<p><strong>自适应双向置换(ABD)方法</strong></p>
<p>为了应对半监督医学图像分割中的一致性学习挑战，研究者们提出了一种创新的自适应双向置换（ABD）方法。该方法的核心在于通过设计双向置换操作，生成多样化的训练样本，从而提高模型的一致性学习能力和性能。</p>
<p>在ABD方法中，首先针对未标记数据设计了基于可靠预测置信度的双向补丁置换。具体而言，对于每个未标记的图像，模型会先对其进行预测，并根据预测结果的置信度将图像划分为可靠区域和不可靠区域。随后，在可靠区域内选择具有高置信度的补丁，并在不可靠区域内选择具有低置信度的补丁进行置换。这种双向置换操作有助于抑制不可控区域的影响，同时保留输入扰动对模型训练的积极作用。</p>
<p><strong>逆置信度双向置换操作</strong></p>
<p>此外，为了进一步增强模型对潜在不可控内容的学习能力，研究者们还提出了针对标记图像的逆置信度双向置换操作。对于每个标记图像，模型同样会先对其进行预测，并根据预测结果的置信度将图像划分为高置信度区域和低置信度区域。然后，在高置信度区域内选择具有低置信度的补丁（即相对不可靠的补丁），在低置信度区域内选择具有高置信度的补丁（即相对可靠的补丁）进行置换。这种逆置信度双向置换操作能够生成包含更多不可靠信息的样本，从而促使模型学习如何更好地处理这些潜在的不可控内容。</p>
<p>通过这两种置换操作，ABD方法能够生成多样化的训练样本，这些样本不仅包含了原始的图像信息，还引入了额外的扰动和不确定性。这些扰动和不确定性有助于模型在训练过程中学习到更加鲁棒和泛化的特征表示，从而提高其在一致性学习任务中的性能。</p>
<h2 id="QuadMamba">QuadMamba</h2>
<blockquote>
<p>Xie F, Zhang W, Wang Z, et al. QuadMamba: Learning Quadtree-based Selective Scan for Visual State Space Model[J]. arXiv preprint arXiv:2410.06806, 2024.</p>
</blockquote>
<h2 id="MemSAM">MemSAM</h2>
<blockquote>
<p>Deng X, Wu H, Zeng R, et al. MemSAM: Taming Segment Anything Model for Echocardiography Video Segmentation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024: 9622-9631.</p>
</blockquote>
<p><strong>引言</strong></p>
<p>根据世界卫生组织（WHO）的统计，心血管疾病是全球死亡的主要原因。超声心动图是评估心血管功能的重要而独特的工具。由于其便携性、低成本和实时性，超声心动图通常被用作临床实践中的一线检查方法。然而，超声心动图通常需要经验丰富的医生进行手动评估，评估质量严重依赖于医生的专业知识。因此，手动评估之间和观察者之间的差异往往很大。此外，评估需要手动跟踪心室大小，这既费力又费时，而且容易出错。在这方面，临床实践非常需要自动化评估方法</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20241205155220803.png" srcset="/img/newloading.gif" lazyload alt="图 1. 超声心动图视频分割的挑战：（a）轮廓模糊，（b）斑点噪声，以及（c-d）跨帧（同一视频的两帧）的比例变化。"></p>
<p>超声心动图评估和诊断通常基于对射血分数和心室容积的解释，这需要从超声心动图视频中准确分割出左心室心内膜等关键结构。然而，自动超声心动图分割一直是一项具有挑战性的任务。</p>
<p>首先，如图 1 (a,b) 所示，由于超声成像的限制，有很多不利因素影响超声心动图视频的质量，例如低信噪比、斑点噪声、边缘丢失以及由致密肌肉和肋骨等结构引起的阴影，难以识别关键解剖结构的边界。其次，视频内和视频之间的心脏结构形状和尺度变化很大（见图 1 (c,d)）。最后，超声心动图视频的注释是一项劳动密集且耗时的工程，因此医生通常只注释收缩末期和舒张末期帧。最后，我们必须对注释有限且稀疏的超声心动图视频进行分割。</p>
<p>近年来，许多深度学习方法被提出用于超声心动图视频分割，但由于超声视频质量低、标注有限，这些方法仍然无法取得令人满意的效果。最近，一种大型视觉模型——Segment Anything Model (SAM) 被提出并在许多自然图像分割任务中取得了显著的成功。</p>
<p>一些研究人员试图将其应用于医学图像分割任务，以利用 SAM 强大的表征能力来缓解训练样本不足的问题。然而，这些研究大多集中在二维图像上，如何将 SAM 应用于医学视频分割仍是一项尚未探索且具有挑战性的任务。将 SAM 直接应用于视频会忽略时间线索，并可能导致时间不一致的分割。例如，如图 1 所示，快速变化的超声心动图视频在目标物体的形状和尺度上存在明显的时间不连续性。此外，大量斑点噪声和伪影造成的边界模糊将极大地阻碍 SAM 释放其表征能力。</p>
<p>在本文中，我们通过将 SAM 应用于医学视频提出了一种新颖的超声心动图视频分割模型，与自然视频相比，医学视频具有一些独特的特征。我们模型的核心技术是一种时间感知和抗噪声的提示方案。</p>
<p>具体来说，我们使用包含空间和时间信息的时空记忆来提示当前帧的分割，因此我们将提出的模型称为 MemSAM。在提示过程中，携带时间线索的记忆会逐帧顺序提示视频分割。同时，随着记忆提示传播高级特征，它避免了由掩码传播引起的错误识别问题并提高了表示一致性。为了应对斑点噪声的挑战，我们提出了一种记忆强化机制，该机制利用预测的掩码来提高记忆质量，然后再进行存储。我们在 SAMUS（一种基于 SAM 的医学基础模型）上构建了我们的模型，这使我们的模型更适应医疗数据。最后，我们在两个公开可用的数据集上进行了广泛的实验。我们的贡献可以总结如下：</p>
<ul>
<li>我们提出了一种基于 SAM 的新型超声心动图视频分割模型。我们模型的核心组件是一种新的提示方法，它能够提供空间和时间线索，以提高表示一致性和分割准确性。</li>
<li>我们进一步提出了记忆强化模块，在存储记忆之前对其进行增强，从而减轻记忆提示过程中斑点噪声和运动伪影的不利影响。</li>
<li>我们在两个公共数据集上对我们的方法进行了广泛的评估，与现有模型相比，我们的模型表现出了最先进的性能。特别是，我们的模型在注释有限的情况下实现了与完全监督方法相当的性能。</li>
</ul>
<p><strong>实验</strong></p>
<p>我们在两个广泛使用的公开超声心动图数据集 CAMUS 和 EchoNet-Dynamic 上评估了我们的方法。</p>
<p><strong>CAMUS 数据集</strong>包含 500 个案例，其中包括 2D 心尖双腔和心尖四腔视图视频。CAMUS 为所有帧提供注释。</p>
<p><strong>EchoNet-Dynamic 数据集</strong>包含 10,030 个 2D 心尖双腔视图视频。每个视频以积分的形式提供左心室的面积。仅标记收缩末期和舒张末期。</p>
<p>为了全面评估我们的方法在半监督视频分割中的有效性，CAMUS 数据集被改编为两个变体：CAMUS-Full 和 CAMUS-Semi。CAMUS-Full 在训练期间使用所有帧的注释，而 CAMUS-Semi 仅使用舒张末期 (ED) 和收缩末期 (ES) 帧的注释。在测试期间，这两个数据集都使用完整的注释进行评估。我们从数据集中均匀采样视频，将它们裁剪为每帧 10 帧。裁剪确保 ED 帧是第一帧，ES 帧是最后一帧，分辨率调整为 256×256。对于 CAMUS 数据集，我们按 7:1:2 的比例将其分为训练集、验证集和测试集，而我们对 EchoNet-Dynamic 数据集使用原始分割。</p>
<p>我们采用了广泛使用的指标，例如平均 Dice 系数 (mDice) 和平均并集 (mIoU) 进行分割评估，以及豪斯多夫距离-95% (HD95) 和平均对称表面距离 (ASSD)。我们还报告了这些指标的标准差。此外，我们还报告了左心室射血分数 (LVEF) 的三个统计指标。我们根据 CAMUS 数据集中提供的辛普森双平面圆盘方法 (SMOD) 估计预测 LVEF。</p>
<p>请注意，不同的实施方法会对最终的 LVEF 结果产生重大影响。SMOD 从心尖二腔和四腔视图的舒张末期和收缩末期时间实例估计 LVEF。与辛普森的单平面规则相比，SMOD 的估计解决方案更准确、更可靠。对于预测和真实 LVEF，我们计算皮尔逊相关系数 (corr)、平均偏差 (bias) 和标准误差 (std)。</p>
<p><strong>与最先进方法的比较</strong></p>
<p>我们广泛选取了不同类型的比较方法，包括传统图像分割模型和医学基础模型。三种传统图像分割模型分别为基于CNN的UNet、基于Transformer的SwinUNet和CNN-Transformer混合的H2Former。医学适应的SAM模型包括MedSAM、MSA、SAMed、SonoSAM和SAMUS。其中SonoSAM和SAMUS专注于超声图像。</p>
<p><strong>定量比较。</strong> 定量比较结果如表 1 所示。在这些最先进的方法中，H2Former 和 SAMUS 在两个数据集上表现相对较好，分别得益于 CNN-Transformer 架构和超声图像优化。然而，如果不利用稀缺注释下视频的时间属性，这些模型仍然落后于我们的方法。实验验证了我们的方法在有限的注释下实现了最先进的性能。</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20241205161005071.png" srcset="/img/newloading.gif" lazyload alt="image-20241205161005071"></p>
<p>为了进一步评估我们的方法，我们在 CAMUS-Semi 和 CAMUS-Full 数据集上以相同的设置对其进行了比较。结果如图 5 所示。可以看出，UNet 和 H2Former 等传统方法以及 SonoSAM 和 SAMUS 等超声波专业方法在完整注释的情况下恢复了不错的结果。虽然我们的方法从半监督到全监督设置都有边际收益，但它在这两种情况下仍然优于其他竞争对手。值得注意的是，医学基础模型需要在完全监督下逐帧提示，而我们只需要一个点提示。实验验证了我们的方法使用更少的外部提示实现了与稀疏标签的完整注释相当的性能。</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20241205161308103.png" srcset="/img/newloading.gif" lazyload alt="图 5. 所提出的方法与最先进的方法在 CAMUS-Semi 和 CAMUS-Full 数据集上的分割性能"></p>
<p><strong>结论</strong></p>
<p>在本文中，我们提出了一种用于超声心动图视频分割的新型半监督视频分割框架，旨在有效地将 SAM 扩展到视频领域，并在有限的注释和提示下实现与全监督相当的性能。然而，当初始帧图像非常差时，我们的方法会导致整个视频序列无法准确分割。未来的研究可以研究实现更稳健初始化的技术，并在更多领域测试我们的方法的有效性，并可以进一步探索降低计算成本和轻量化模型的方法。</p>
<h2 id="CAF-MambaSegNet">CAF-MambaSegNet</h2>
<p>2D 不好改，之后再看</p>
<p>提出了一种名为CAF-MambaSegNet的无卷积和自注意力的语义分割网络，通过设计Mamba-based Channel Aggregator和Spatial Aggregator以及Linearly Interconnected Factorized Mamba (LIFM) Block，展示了在心脏图像分割中不依赖传统CNN和Transformer的方法，旨在减少计算复杂度和参数数量。</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20241108172721598.png" srcset="/img/newloading.gif" lazyload alt="image-20241108172721598"></p>
<p><strong>创新点：</strong></p>
<p>1.提出了无卷积和自注意力的CAF-MambaSegNet网络，创新地使用Mamba-based Channel Aggregator和Spatial Aggregator进行特征提取。</p>
<p>2.引入了Linearly Interconnected Factorized Mamba (LIFM) Block，以减少计算复杂度并增强决策函数。</p>
<p>3.展示了在心脏图像分割任务中，线性复杂度和减少参数数量的方法可以取得与现有方法相当的效果。</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20241108172929244.png" srcset="/img/newloading.gif" lazyload alt="image-20241108172929244"></p>
<h2 id="LKM-UNet">LKM-UNet</h2>
<div class = "note note-success">MICCAI 2024</div>
<p>可以用于3D，但不好改</p>
<p>作者提出了一种新的基于 Mamba 的 UNet 模型(LKM-UNet)，用于 2D 和 3D 医学图像分割</p>
<p><strong>摘要</strong></p>
<p>LKM-UNet 的一个区别特征是其使用大型 Mamba 内核，与基于小内核的 CNN 和 Transformers 相比，在局部空间建模方面表现出色，同时保持了与二次复杂性的自注意力相比的优越效率。此外，我们设计了一种新颖的层次化和双向 Mamba 块，以进一步增强 Mamba 对视觉输入的全局和邻域空间建模能力。</p>
<p><strong>方法</strong></p>
<p>LKM-UNet</p>
<p>除了常见的 UNet 组成，包括深度可分离卷积、编码器下采样层、解码器上采样层和跳跃连接外，LKM-UNet 通过在编码器中插入提出的大内核 Mamba（LM）块来改进 UNet 的结构。</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20241024160346858.png" srcset="/img/newloading.gif" lazyload alt="Fig. 1. An overview of our proposed LKM-UNet."></p>
<p>在每个阶段之后，生成的特征图  被编码为 (2C,D/2,H/2,W/2)</p>
<p>LM-block</p>
<p>LM 块是用于进一步空间建模每个阶段不同尺度的特征图的核心组件。与之前使用 CNN 进行局部像素级建模和 Transformer 进行长距离块级依赖性建模的方法不同，LM 块可以同时完成像素级和块级建模，得益于 Mamba 的线性复杂性。更重要的是，较低的复杂性允许设置更大的内核（窗口）以获得更大的感受野，这将提高局部建模的效率.</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20241024161331002.png" srcset="/img/newloading.gif" lazyload alt="image-20241024161331002"></p>
<p>在大内核分割策略下，感受野被扩大，模型可以获得更多局部像素的细节。然而，图像被分割成非重叠的子内核。因此，我们需要一个机制来实现不同子内核之间的通信，以进行长距离依赖性建模。块级 SSM（PaM）。我们引入了一个块级 SSM 层，以在不同的子内核之间传递信息.</p>
<p>与基于前向扫描方向 SSM 层的原始 Mamba 块不同，LM 块中的每个 SSM 层（包括 PiM 和 PaM）都是双向的。图 2(b) 显示了差异。在原始 Mamba 中，作为一个连续模型，一些信息遗忘发生在早期进入的元素上，而最后进入 Mamba 的元素将保留更多的信息。因此，具有单一扫描方向的原始 Mamba 将更多地关注后部块，而不是通常包含更多器官和病变的特征图的中心区域。为此，我们提出了一个双向 Mamba 结构，通过同时进行前向和后向扫描并叠加输出结果。BiM 有两个优点。首先，模型可以更多地关注图像中心区域的信息块，而不是角落区域。其次，对于每个块，绝对位置信息和与其他块的相对位置信息可以被网络很好地建模。</p>
<h2 id="Deformable-Attention">Deformable Attention</h2>
<blockquote>
<p>Xia Z, Pan X, Song S, et al. Vision transformer with deformable attention[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022: 4794-4803.</p>
</blockquote>
<h2 id="Serp-Mamba">Serp-Mamba</h2>
<blockquote>
<p>Wang H, Chen Y, Chen W, et al. Serp-Mamba: Advancing High-Resolution Retinal Vessel Segmentation with Selective State-Space Model[J]. arXiv preprint arXiv:2409.04356, 2024.</p>
</blockquote>
<p>蛇形交织自适应（SIA）扫描机制和模糊度驱动的双重重校准（ADDR）模块</p>
<p>消融实验</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20250403150551337.png" srcset="/img/newloading.gif" lazyload alt="image-20250403150551337"></p>
<p>（i）基线：我们采用经典的U形U-Mamba骨干网络作为基线模型;（ii）M1：我们包括SIA扫描机制，并且没有ADDR模块，以测试SIA是否能够使Mamba块在沿沿着可学习的血管路径扫描之后提高分割的准确性;（iii）M2：我们去除了SIA扫描机制，并在M1的基础上加入了ADDR模块，以验证ADDR在解决类别不平衡问题和增强血管连续性; (iv) ours：我们的Serp-Mamba包括SIA扫描机制和ADDR模块。</p>
<h2 id="MaIR">MaIR</h2>
<blockquote>
<p>Li B, Zhao H, Wang W, et al. MaIR: A Locality-and Continuity-Preserving Mamba for Image Restoration[J]. arXiv preprint arXiv:2412.20066, 2024.</p>
</blockquote>
<p>消融对比几种扫描方式</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20250403162345395.png" srcset="/img/newloading.gif" lazyload alt="image-20250403162345395"></p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20250403162051390.png" srcset="/img/newloading.gif" lazyload alt="image-20250403162051390"></p>
<h2 id="Dual-Correlation-aware-Mamba">Dual Correlation-aware Mamba</h2>
<p>Dual Correlation-Aware Mamba  for Microvascular Obstruction  Identification in Non-contrast Cine  Cardiac Magnetic Resonance</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20251119173559189.png" srcset="/img/newloading.gif" lazyload alt="image-20251119173559189"></p>
<p>该研究提出双相关感知 Mamba（DCM）方法，实现非对比 cine 心脏磁共振（CMR）的微血管阻塞（MVO）识别，解决现有方法运动特征提取不足和忽视区域壁运动异常（RWMA）的问题，性能优于现有竞品，为肾损伤患者提供了可行的非对比检测方案。</p>
<p><strong>研究背景与核心问题</strong></p>
<ul>
<li>MVO 是急性心肌梗死的关键预后因素，晚期钆增强（LGE）-CMR 是诊断金标准，但不适用于占比 20% 的肾损伤患者。</li>
<li>非对比 cine CMR 可捕捉心脏周期运动，有望替代 LGE，但 MVO 在单帧不可见，需分析多帧运动特征。</li>
<li>现有方法存在两大局限：隐式建模运动动态导致特征提取不充分，忽视 MVO 引发的 RWMA 这一关键诊断依据。</li>
</ul>
<p><strong>核心方法设计</strong></p>
<ul>
<li><strong>整体框架</strong>：通过 3D CNN 提取 cine 序列特征，经两阶段 DCM 块（含 AFC 和 DFC 模块）增强运动特征，最终通过平均池化和分类器输出 MVO 检测结果。</li>
<li><strong>Adjacent Frame Correlation（AFC）模块</strong>：计算相邻帧间相关性，预测像素位移偏移量，显式建模心脏运动动态，结合双向时间 Mamba 聚合特征。</li>
<li><strong>Diastolic Frame Correlation（DFC）模块</strong>：以舒张期帧为全局参考，学习其与其他帧的相关性，突出 RWMA，通过双向空间 Mamba 聚合运动信息。</li>
<li><strong>损失函数</strong>：采用交叉熵损失 + 均值平方误差损失（权重 0.05），结合粗粒度掩码正则化优化训练。</li>
</ul>
<p><strong>实验结果</strong></p>
<ul>
<li><strong>数据集</strong>：816 例急性心肌梗死患者数据，按训练集（550 例）和测试集（266 例）随机划分，以 AUC、特异性、准确率等为评价指标。</li>
<li><strong>性能对比</strong>：DCM 的 AUC 达 0.7687，在各项指标上均超过 VST、CGMR 等现有方法，且参数量（39.91M）更具优势。</li>
<li><strong>消融实验</strong>：AFC 和 DFC 模块均对性能有显著贡献；舒张期帧是最优参考帧；两阶段框架结构实现最佳性能；可学习偏移量和最优窗口半径（[2,1]）提升了运动建模效果。</li>
</ul>
<p><strong>结论与展望</strong></p>
<ul>
<li>DCM 通过显式建模运动动态和参考舒张期帧引导学习，有效提升了非对比 cine CMR 的 MVO 识别能力。</li>
<li>未来将进一步优化 MVO 轮廓描绘，并探索其与其他引发心肌异常的心脏病变的鉴别方法。</li>
</ul>
<h2 id="XFMamba">XFMamba</h2>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20251119172536127.png" srcset="/img/newloading.gif" lazyload alt="image-20251119172536127"></p>
<p>XFMamba 是一款基于状态空间模型（Mamba）的纯 Mamba 跨融合架构，专为多视图医学图像分类设计，在 MURA、CheXpert、CBIS-DDSM 三大数据集上表现优于现有卷积和 Transformer 基方法，兼顾分类精度与计算效率。</p>
<p><strong>核心贡献</strong></p>
<ol>
<li>首次将 Mamba（状态空间模型）成功应用于多视图医学图像分类任务。</li>
<li>提出两阶段 Mamba 融合机制，高效提取并无缝整合多视图信息。</li>
<li>经三大不同临床场景数据集验证，确立了 Mamba 在多视图医学成像领域的性能基准。</li>
</ol>
<p><strong>架构设计</strong></p>
<ul>
<li>
<p><strong>四阶段多尺度编码器</strong>：以 VMamba 为骨干，含两个并行分支，分别处理两种不同视图的输入图像。通过图像分块、三次下采样和视觉状态空间模块（VSSM），提取四级多尺度特征。</p>
</li>
<li>
<p>两阶段融合模块：</p>
<ol>
<li>
<p>浅层融合（CVSM 块）：通过跨视图交织机制交换局部特征，结合通道注意力重加权，增强视图间局部关联。</p>
<p>CVSM 的核心创新是<strong>基于通道掩码的跨视图交织机制</strong>，解决 “局部跨视图特征关联捕捉” 与 “计算效率” 的矛盾：</p>
<ul>
<li>设计二进制通道掩码<code>M(C)</code>（Eq.4）：对两个视图的深层特征（如<code>Xv1⁴</code>、<code>Xv2⁴</code>），按通道奇偶性进行 “选择性交织”—— 偶数通道替换为另一视图的对应通道，奇数通道保留本视图通道。这种方式无需额外参数或复杂计算，即可实现 “视图间局部特征交换”，避免传统交叉注意力的高计算成本。</li>
<li>引入 “交叉通道注意力重加权”：复用 Squeeze-and-Excitation（SE）机制，但创新地将 “单视图自注意力” 改为 “跨视图互注意力”—— 用视图 v1 的全局上下文注意力来调整视图 v2 的通道权重，反之亦然。这一设计确保 “融合后的特征能优先保留两视图中与病灶相关的关键信息”，而非简单平均</li>
</ul>
</li>
<li>
<p>深层融合（MVCM 块）：聚合浅层融合输出，通过多视图选择性扫描和融合乘法机制，生成全局整合的融合特征。</p>
<p>CVSM 仅解决 “局部特征交互”，而 MVCM 针对 “全局多视图信息整合” 设计，核心创新在于<strong>多分支协同与状态空间模型（SSM）的定制化改造</strong>：</p>
<ul>
<li>三分支输入设计：将 CVSM 输出的两视图特征（Xv1⁵、Xv2⁵）与 “两视图直接融合特征” 作为三个并行分支，同时输入 MVCM。这种设计避免 “单一分支丢失视图特异性信息”，确保融合时既保留单视图细节，又能捕捉全局关联。</li>
<li>定制化多视图 SSM 模块：改造传统 SSM 的 “单序列处理” 为 “多序列协同处理”—— 引入融合分支的系统矩阵<code>C_fuse</code>，用其解码两个单视图分支的隐藏状态（Eq.5），即 “用全局融合特征的上下文来引导单视图特征的优化”（🔶1-46、🔶1-49）。这一改造让 SSM 从 “单视图长距离依赖建模” 升级为 “多视图全局关联建模”，确保融合特征的整体性。</li>
<li>融合乘法机制：对归一化后的单视图特征与融合特征进行乘法交互，自适应学习 “融合特征对单视图特征的增益权重”，而非传统的简单加法或拼接（🔶1-50）。这种方式能动态强化 “两视图共识的关键特征”（如病灶区域），抑制 “视图特异性噪声”（如成像 artifacts）</li>
</ul>
</li>
</ol>
</li>
</ul>
<p><strong>实验验证</strong></p>
<ul>
<li><strong>数据集与设置</strong>：覆盖肌肉骨骼 X 线、胸部 X 线、乳腺钼靶三大场景，统一将图像 resize 为 224×224，基于 PyTorch 训练，提供 tiny、small、base 三种模型变体。</li>
<li><strong>性能表现</strong>：small 和 base 变体在所有数据集上 AUROC 值最高；tiny 变体参数更少（39.29M），计算量（FLOPs）最低，仍在 MURA、CheXpert 数据集上优于多数对比方法。</li>
<li><strong>消融实验</strong>：两阶段融合模块缺一不可，移除后性能下降 0.4%~0.92%；多视图融合比单视图（提升 1.03%~2.17%）、早期 / 晚期融合（提升 0.92%~0.94%）更有效。</li>
</ul>
<h2 id="DGMIR">DGMIR</h2>
<p>DGMIR: Dual-Guided Multimodal  Medical Image Registration Based  on Multi-view Augmentation and On-Site  Modality Removal</p>
<p><img src="https://cdn.jsdelivr.net/gh/52HZMercury/img/blog/image-20251119172922776.png" srcset="/img/newloading.gif" lazyload alt="image-20251119172922776"></p>
<h4 id="整体结构">整体结构</h4>
<ul>
<li>编码器为四阶段架构，输出两组多尺度特征图；解码器采用粗到细策略，每阶段整合 MFRG 和 MORG 模块。</li>
<li>形变场预测采用迭代融合策略，结合前一阶段子形变场与当前阶段输出，保证连续性。</li>
</ul>
<h4 id="核心模块原理">核心模块原理</h4>
<ul>
<li>MFRG：融合特征通道的均值、最大值统计信息，计算模态间交叉相关性和模态内自相关性，通过校准因子自适应增强有效特征。</li>
<li>MORG：结合普通卷积与空洞卷积提取多感受野特征，通过均值卷积分离模态特征并移除，保留结构信息。</li>
</ul>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F/" class="category-chain-item">医学影像</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">#深度学习</a>
      
        <a href="/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/">#语义分割</a>
      
        <a href="/tags/%E8%AE%BA%E6%96%87/">#论文</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>ReadPapers</div>
      <div>http://example.com/2024/09/06/readpapers/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Mercury</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年9月6日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/09/26/SimLVSegWithMamba/" title="SimLVSeg With Mamba 实验">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">SimLVSeg With Mamba 实验</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/09/03/UltrasoundCardiogram/" title="超声心动图调研">
                        <span class="hidden-mobile">超声心动图调研</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <div style="font-size: 0.85rem"> <span id="timeDate">载入天数...</span> <span id="times">载入时分秒...</span> <script src="/js/duration.js"></script> </div> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>






  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>

  <!-- 樱花特效 -->
  <script type="text/javascript">
    var windowWidth = $(window).width();
    if (windowWidth > 480) {
      document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>');
    }
  </script>

</body>
</html>
